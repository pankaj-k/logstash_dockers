# Create a CloudWatch Log Group for Logstash logs generated by ECS tasks running Logstash containers.
# The log group is created using the terraform-aws-modules/cloudwatch/aws module. 
module "logstash_logs" {
  source = "terraform-aws-modules/cloudwatch/aws//modules/log-group"
  #version = "~> 5.7.1"

  name              = "/ecs/logstash"
  retention_in_days = 7

  tags = {
    Name        = "logstash-log-group"
    Environment = "dev"
  }
}

# Cluster is a module inside the ecs module.
module "ecs_cluster" {
  source = "terraform-aws-modules/ecs/aws//modules/cluster" # terraform-aws-modules/ecs/aws//modules/service
  name   = "ecs-fargate-logstash-cluster"
  #   capacity_providers = ["FARGATE", "FARGATE_SPOT"]
  default_capacity_provider_strategy = {
    FARGATE = {
      weight = 50
      base   = 20
    }
    FARGATE_SPOT = {
      weight = 50
    }
  }

  tags = {
    Environment = "dev"
    Project     = "ecs-fargate-logstash-cluster"
  }
}

module "ecs_service" {
  source = "terraform-aws-modules/ecs/aws//modules/service"
  #version = "~> 5.11.3"

  name        = "logstash-service"
  cluster_arn = module.ecs_cluster.arn

  cpu    = 512  # adjust as needed
  memory = 1024 # adjust as needed


  # Auto-create execution role
  create_task_exec_iam_role = true
  task_exec_iam_role_policies = {
    ecs_execution = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
    ecr_access    = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  }

  #   # Auto-create task role (useful if Logstash needs AWS API access)
  #   create_task_iam_role = true
  #   task_iam_role_policies = {
  #     kms_decrypt = aws_iam_policy.kms_decrypt_policy.arn
  #   }

  #   # Security group inline
  #   create_security_group = true
  #   security_group_name   = "logstash-sg"

  # Each task runs containers. Here we have only one container - logstash.
  # You can define multiple containers inside container_definitions. 
  # Module restricts the container count to 10
  container_definitions = {
    logstash = {
      cpu       = 512
      memory    = 1024
      essential = true
      image     = "${module.ecr.repository_url}:latest"

      security_group_ingress_rules = {
        alb_ingress = {
          description                  = "Allow ALB to reach Logstash"
          from_port                    = 8080
          to_port                      = 8080
          ip_protocol                  = "tcp"
          referenced_security_group_id = module.alb.security_group_id
      } }

      security_group_egress_rules = {
        description = "Allow all outbound"
        ip_protocol = "-1"
        cidr_ipv4   = ["0.0.0.0/0"]
      }

      portMappings  = [
        {
          containerPort = 8080
          hostPort      = 8080
          protocol      = "tcp"
        }
      ]

      # Health check for the container.
      # ECS health check → ensures the process inside container is healthy.
      # ELB health check → ensures clients only hit working tasks over the network.
      # For production workloads, you should have both.
      # If you just have ECS health check, ECS may keep traffic flowing to a broken task (because LB doesn’t know).
      # If you just have ALB health check, ECS may think the container is fine (process is alive) but LB won’t route traffic if networking is broken.

      healthCheck = {
        command = [
          "CMD-SHELL",
          "curl -f http://localhost:8080 || exit 1"
        ]
        interval    = 30 # Run the health check every 30 seconds.
        timeout     = 10 # Allow up to 10 seconds for the health check to complete.
        retries     = 3  # 3 consecutive failures before marking the container UNHEALTHY.
        startPeriod = 60 # Give the container 60 seconds to bootstrap before starting health checks.
      }

      log_configuration = {
        logDriver = "awslogs"
        options = {
          awslogs-group         = module.logstash_logs.cloudwatch_log_group_name
          awslogs-region        = var.region
          awslogs-stream-prefix = "logstash"
        }
      }
    }
  }

  launch_type = "FARGATE"

  
  desired_count = 2 
  # At service level we ask for 2 tasks.
  # base = 20 means "place 20 tasks on FARGATE first"
  # We asked for 2 total tasks. So with base=20, both will go to FARGATE.
  # If we asked for 100 tasks, then 20 would go to FARGATE, Remaining = 100 - 20 = 80 tasks
  # Split 60/40 of 80 = 48 tasks to FARGATE and 32 tasks to FARGATE_SPOT.
  # Final tally = 20 + 48 = 68 tasks on FARGATE and 32 tasks on FARGATE_SPOT.

  autoscaling_policies = {
    cpu_scale_out = {
      policy_type = "TargetTrackingScaling"
      target_tracking_scaling_policy_configuration = {
        predefined_metric_specification = {
          predefined_metric_type = "ECSServiceAverageCPUUtilization"
        }
        target_value       = 50
        scale_in_cooldown  = 60
        scale_out_cooldown = 60
      }
    }
  }

  subnet_ids       = module.vpc.private_subnets
  assign_public_ip = false

  # Use existing ALB (better practice than creating inside ECS module)
  load_balancer = {
    service = {
      target_group_arn = aws_lb_target_group.logstash_tg.arn
      container_name   = "logstash"
      container_port   = 8080
    }
  }

  tags = {
    Name        = "logstash-service"
    Environment = "dev"
  }
}
